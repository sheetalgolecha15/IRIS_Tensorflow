{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train= pd.read_csv(\"iris_training.csv\",names=[\"sepal_lenght\",\"sepal_width\",\"petal_length\",\"petal_width\",\"class\"])\n",
    "test= pd.read_csv(\"iris_test.csv\",names=[\"sepal_lenght\",\"sepal_width\",\"petal_length\",\"petal_width\",\"class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train[[\"sepal_lenght\",\"sepal_width\",\"petal_length\",\"petal_width\"]]\n",
    "test_x=test[[\"sepal_lenght\",\"sepal_width\",\"petal_length\",\"petal_width\"]]\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sepal_lenght    float64\n",
       "sepal_width     float64\n",
       "petal_length    float64\n",
       "petal_width     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x=train_x.convert_objects(convert_numeric=True)\n",
    "test_x=test_x.convert_objects(convert_numeric=True)\n",
    "\n",
    "test_x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.742781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           class\n",
       "count  30.000000\n",
       "mean    1.000000\n",
       "std     0.742781\n",
       "min     0.000000\n",
       "25%     0.250000\n",
       "50%     1.000000\n",
       "75%     1.750000\n",
       "max     2.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train_y=pd.DataFrame(train['class'])\n",
    "test_y=pd.DataFrame(test['class'])\n",
    "train_y=train_y.convert_objects(convert_numeric=True)\n",
    "test_y=test_y.convert_objects(convert_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x=train_x.iloc[1:]\n",
    "test_x=test_x.iloc[1:]\n",
    "train_y=train_y.iloc[1:]\n",
    "test_y=test_y.iloc[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_x=train_x.shape[1]\n",
    "nodes_y=train_y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the neural netwwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "learning_rate=0.01\n",
    "g=tf.Graph()\n",
    "with g.as_default():\n",
    "    x=tf.placeholder(tf.float32,[None,nodes_x],name=\"x\")\n",
    "    y=tf.placeholder(tf.float32,[None,nodes_y],name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h1=5\n",
    "h2=10\n",
    "h3=5\n",
    "\n",
    "with tf.name_scope('Neural_Nt'):\n",
    "    FC1=tf.contrib.layers.fully_connected(inputs=x,num_outputs=h1,\n",
    "                                          activation_fn=tf.nn.relu,scope=\"Fully_Conn1\")\n",
    "    FC2=tf.contrib.layers.fully_connected(inputs=\n",
    "                        FC1,num_outputs=h2,activation_fn=\n",
    "                                        tf.nn.relu,scope=\"Fully_Conn2\")\n",
    "    FC3=tf.contrib.layers.fully_connected(inputs=\n",
    "                        FC2,num_outputs=h3,activation_fn=\n",
    "                                        tf.nn.relu,scope=\"Fully_Conn3\")\n",
    "    predict_y=tf.contrib.layers.fully_connected(inputs=FC3,num_outputs=nodes_y,activation_fn=tf.nn.softmax,scope=\"Out\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('cost'):\n",
    "    cost=tf.losses.softmax_cross_entropy(onehot_labels=y,logits=predict_y,scope=\"Cost_Function\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    corect_pred=tf.equal(tf.argmax(predict_y,1,name=\"Argmax_pred\"),tf.argmax(y,1,name=\"Y_Pred\"),name=\"Correct_Pred\")\n",
    "    accuracy=tf.reduce_mean(tf.cast(corect_pred,tf.float32,name=\"Cast_Corr_Pred\"),name=\"Accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    optimizer=tf.train.AdagradOptimizer(learning_rate,name=\"Optimizer\").minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "logs=\"log_final\"\n",
    "\n",
    "tf.summary.scalar(\"Loss\",cost)\n",
    "tf.summary.scalar(\"Accuracy\",accuracy)\n",
    "merged_summary3=tf.summary.merge_all()\n",
    "\n",
    "sess=tf.InteractiveSession(graph=g)\n",
    "init=tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(init)\n",
    "    writer=tf.summary.FileWriter(logs,graph=tf.get_default_graph())\n",
    "    \n",
    "    train_epochs=1000\n",
    "    for epoch in range(train_epochs):\n",
    "       # print(train_y)\n",
    "        _,c,summary=sess.run([optimizer,cost,merged_summary3],feed_dict={x:train_x,y:train_y})\n",
    "        writer.add_summary(summary,epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reduce_mean(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to run tensor board type \n",
    "\n",
    "1. python -m tensorboard\n",
    "2.tensorboard --logdir ./log_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
